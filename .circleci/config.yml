version: 2.1
jobs:
  build:
    docker:
      - image: debian:stretch

    environment:
      PROJECT: neo4j-helm
      CLUSTER: ci-test
      ZONE: us-central1-a
      NODES: 3
      NAME_CLUSTERED: testrunc
      NAME_STANDALONE: testrunsa
      BUILD_ARTIFACTS: build

    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: Tooling pre-requisites
          command: |
            # Secure software install
            apt-get update && apt-get install -y apt-transport-https ca-certificates curl gnupg2 software-properties-common
            
            # Google Cloud stuff
            export CLOUD_SDK_REPO="cloud-sdk-$(lsb_release -c -s)"
            echo "deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
            curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
            
            # Docker stuff
            curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -
            add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"

            apt-get update
            EXTRA_NEEDED_TOOLS="wget make gettext-base jq"

            # Docker not yet needed....
            # DOCKER="docker-ce docker-ce-cli containerd.io"

            apt-get install -y google-cloud-sdk $EXTRA_NEEDED_TOOLS

            # We will install local tools so add those to path.
            echo "export PATH=./tools:.:$PATH" >> $BASH_ENV
            mkdir $BUILD_ARTIFACTS
            mkdir tools

      - run: 
          name: Setup GCP Tooling
          command: |
            echo $GCLOUD_SERVICE_KEY > service-key.json
            gcloud auth activate-service-account \
                $GCLOUD_SERVICE_ACCOUNT \
                --key-file=service-key.json
            gcloud auth configure-docker

      - run:
          name: Kubectl Setup
          command: |
             cd tools
             curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
             chmod +x kubectl
             kubectl --help
                
      - run:
          name: GKE Setup / Auth
          command: |
             echo "GKE SETUP"
             export CLUSTER_NAME=$CLUSTER-$CIRCLE_BUILD_NUM
             ./test/provision-k8s.sh $CLUSTER_NAME

      - run:
          name: Install Helm Binaries
          command: |
             cd tools
             curl -LO https://get.helm.sh/helm-v3.2.1-linux-amd64.tar.gz
             tar zxvf helm-v3.2.1-linux-amd64.tar.gz
             mv linux-amd64/helm .
             helm version
      
      - run:
          name: Lint
          command: helm lint . 

      - run:
          name: Create test namespace
          command: |
            cat \<<EOF | kubectl apply -f -
            apiVersion: v1
            kind: Namespace
            metadata:
              name: ns-$CIRCLE_BUILD_NUM
            EOF

      - run:
          name: Package and Install Neo4j-Helm Chart
          command: |
             NAMESPACE=ns-$CIRCLE_BUILD_NUM
             helm package .
             chart_archive=$(ls neo4j*.tgz)
             cp *.tgz $BUILD_ARTIFACTS/

             echo "Installing $chart_archive (CAUSAL CLUSTER TEST SCENARIO)"
             helm install $NAME_CLUSTERED $chart_archive \
                 --namespace $NAMESPACE \
                 --set acceptLicenseAgreement=yes \
                 --set neo4jPassword=mySecretPassword \
                 --set readReplica.numberOfServers=1 \
                 -v 3 | tee -a $BUILD_ARTIFACTS/INSTALL-cluster.txt

             echo "Installing $chart_archive (STANDALONE SCENARIO)"
             helm install $NAME_STANDALONE $chart_archive \
                 --namespace $NAMESPACE \
                 --set acceptLicenseAgreement=yes \
                 --set readinessProbe.initialDelaySeconds=20 \
                 --set livenessProbe.initialDelaySeconds=20 \
                 --set neo4jPassword=mySecretPassword \
                 --set core.standalone=true \
                 -v 3 | tee -a $BUILD_ARTIFACTS/INSTALL-standalone.txt
                     

      #- run:
      #    name: Twiddling our Thumbs
      #    command: |
      #      sleep 60
      #      NAMESPACE=ns-$CIRCLE_BUILD_NUM
      #      kubectl logs --namespace $NAMESPACE \
      #        -l "app.kubernetes.io/name=neo4j,app.kubernetes.io/component=core" | tee -a $BUILD_ARTIFACTS/startlogs.txt

      - run:
          name: Wait for GKE STANDALONE deployment to succeed and become ready
          command: |
              NAMESPACE=ns-$CIRCLE_BUILD_NUM
              kubectl rollout status --namespace $NAMESPACE StatefulSet/$NAME_STANDALONE-neo4j-core --watch | tee -a $BUILD_ARTIFACTS/wait.txt
      
      # We're going to test standalone first because it forms faster than cluster.  In the background,
      # cluster is still forming....
      - run: 
          name: Test STANDALONE
          command: |
              NAMESPACE=ns-$CIRCLE_BUILD_NUM
              helm test $NAME_STANDALONE --namespace $NAMESPACE --logs | tee -a $BUILD_ARTIFACTS/TEST-STANDALONE.txt

      - run:
          name: Wait for GKE CLUSTERED deployment to succeed and become ready
          command: |
             NAMESPACE=ns-$CIRCLE_BUILD_NUM
             kubectl rollout status --namespace $NAMESPACE StatefulSet/$NAME-cluster-neo4j-core --watch | tee -a $BUILD_ARTIFACTS/wait.txt

      - run:
          name: Test
          command: |
            NAMESPACE=ns-$CIRCLE_BUILD_NUM
            helm test $NAME_CLUSTERED --namespace $NAMESPACE --logs | tee -a $BUILD_ARTIFACTS/TEST.txt

      - run:
          name: Uninstall / Cleanup
          # Make sure to always run this, particularly if the test fails,
          # to avoid clogging our cluster.
          when: always
          command: |
            echo "TEAR DOWN GKE INSTANCE"
            gcloud container clusters delete $CLUSTER-$CIRCLE_BUILD_NUM \
              --async \
              --zone "$ZONE" \
              --project $PROJECT \
              --quiet

      - store_artifacts:
          path: build